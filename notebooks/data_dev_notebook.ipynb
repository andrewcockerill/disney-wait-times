{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition Development Notebook\n",
    "Notebook for testing functions to download, transform, and store datasets needed for analysis and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holidays\n",
    "from datetime import date\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and transform a single wait time dataset from TouringPlans\n",
    "\n",
    "def fetch_wait_times(url, attraction_name):\n",
    "    \"\"\"Retrieves and formats an attraction wait time dataset from public .csvs made available\n",
    "    by TouringPlans (https://touringplans.com/walt-disney-world/crowd-calendar#DataSets). Output\n",
    "    dataset is transformed to provide pertinent time data and wait times. Missing data is not handled\n",
    "    at this point.\n",
    "    \n",
    "    Args:\n",
    "        url : string\n",
    "            The URL of the dataset\n",
    "            \n",
    "        ride_name : string\n",
    "            Description of the ride\n",
    "            \n",
    "    Returns:\n",
    "        wait_times : DataFrame\n",
    "            The prepared data frame with columns \n",
    "            \n",
    "            ['attraction_name',\n",
    "            'month_of_year',\n",
    "            'hour_of_day',\n",
    "            'year_of_calendar',\n",
    "            'wait_time']\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in the csv file\n",
    "    wait_times = pd.read_csv(\n",
    "        url,\n",
    "        usecols=['datetime','SACTMIN','SPOSTMIN'],\n",
    "        dtype={'datetime':str,'SACTMIN':np.float64,'SPOSTMIN':np.float64}\n",
    "    )\n",
    "    \n",
    "    # Transforms for date elements\n",
    "    wait_times.loc[:,'datetime'] = pd.to_datetime(wait_times.datetime, format='%Y-%m-%d %H:%M:%S')\n",
    "    wait_times['month_of_year'] = wait_times.datetime.dt.month\n",
    "    wait_times['hour_of_day'] = wait_times.datetime.dt.hour\n",
    "    wait_times['year_of_calendar'] = wait_times.datetime.dt.year\n",
    "    wait_times['date_id'] = wait_times.datetime.dt.date\n",
    "    \n",
    "    # Wait time coalesce (use the actual time if available)\n",
    "    wait_times['wait_time'] = wait_times.SACTMIN.combine_first(wait_times.SPOSTMIN)\n",
    "    \n",
    "    # Descriptor\n",
    "    wait_times['attraction_name'] = attraction_name\n",
    "    \n",
    "    # Output data\n",
    "    wait_times = wait_times[['attraction_name','date_id','month_of_year','hour_of_day','year_of_calendar','wait_time']]\n",
    "    return wait_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all datasets and save a local copy\n",
    "\n",
    "def save_touring_plans_data(path):\n",
    "    \"\"\"Function to download all wait time datasets from public .csvs made available\n",
    "    by TouringPlans (https://touringplans.com/walt-disney-world/crowd-calendar#DataSets).\n",
    "    Output is saved as a single consolidated .csv file.\n",
    "    \n",
    "    Args:\n",
    "        path : string\n",
    "            The path to save the .csv file to\n",
    "            \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary of attraction names and .csv urls\n",
    "    url_lookup = {\n",
    "        'Alien Swirling Saucers': 'https://cdn.touringplans.com/datasets/alien_saucers.csv',\n",
    "        'Avatar Flight of Passage': 'https://cdn.touringplans.com/datasets/flight_of_passage.csv',\n",
    "        'DINOSAUR': 'https://cdn.touringplans.com/datasets/dinosaur.csv',\n",
    "        'Expedition Everest': 'https://cdn.touringplans.com/datasets/expedition_everest.csv',\n",
    "        'Kilimanjaro Safaris': 'https://cdn.touringplans.com/datasets/kilimanjaro_safaris.csv',\n",
    "        'Navi River Journey': 'https://cdn.touringplans.com/datasets/navi_river.csv',\n",
    "        'Pirates of the Caribbean': 'https://cdn.touringplans.com/datasets/pirates_of_caribbean.csv',\n",
    "        'Rock n Roller Coaster': 'https://cdn.touringplans.com/datasets/rock_n_rollercoaster.csv',\n",
    "        'Seven Dwarfs Mine Train': 'https://cdn.touringplans.com/datasets/7_dwarfs_train.csv',\n",
    "        'Slinky Dog Dash': 'https://cdn.touringplans.com/datasets/slinky_dog.csv',\n",
    "        'Soarin': 'https://cdn.touringplans.com/datasets/soarin.csv',\n",
    "        'Spaceship Earth': 'https://cdn.touringplans.com/datasets/spaceship_earth.csv',\n",
    "        'Splash Mountain': 'https://cdn.touringplans.com/datasets/splash_mountain.csv',\n",
    "        'Toy Story Mania': 'https://cdn.touringplans.com/datasets/toy_story_mania.csv'     \n",
    "    }\n",
    "    \n",
    "    # Set up output dataframe\n",
    "    out_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through dictionary\n",
    "    for attraction_name, url in url_lookup.items():\n",
    "        context_df = fetch_wait_times(url=url, attraction_name=attraction_name)\n",
    "        out_df = pd.concat([out_df,context_df]).reset_index(drop=True)\n",
    "        \n",
    "    # Save the data as .csv\n",
    "    out_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test saving the file\n",
    "save_touring_plans_data('../data/test_extract.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the file\n",
    "test_df=pd.read_csv('../data/test_extract.csv')\n",
    "test_df = test_df[test_df.attraction_name=='Soarin'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates/Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date, name in sorted(holidays.US(state='CA',years=2019).items()):\n",
    "    print(date, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_days = holidays.US()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['holiday_name'] = test_df.date_id.apply(lambda x:us_days.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pm_string = 'datasetid=GHCND&stationid=GHCND:USW00012815&startdate=2015-01-01&enddate=2015-12-31&datatypeid=TMAX&units=standard&limit=1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data', params=pm_string,\n",
    "                headers=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame.from_dict(r.json()['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = pd.read_csv('../data/noaa_orlando_mco_temps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labor/Economic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us unemployment\n",
    "us_unemp = pd.read_excel('../data/us_unemployment_rates.xlsx',usecols='A:M',skiprows=11)\n",
    "us_unemp = us_unemp.melt(id_vars='Year',value_vars=[i for i in us_unemp.columns if i!='Year'],var_name='month_of_year',\n",
    "                        value_name='unemployment_pct')\n",
    "us_unemp.loc[:, 'month_of_year'] = us_unemp.month_of_year.apply(lambda x:pd.to_datetime(x,format='%b')).dt.month\n",
    "us_unemp.columns = ['year_of_calendar','month_of_year','unemployment_pct']\n",
    "us_unemp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fl unemployment\n",
    "fl_unemp = pd.read_excel('../data/fl_unemployment.xlsx',usecols='A:M',skiprows=10)\n",
    "fl_unemp = fl_unemp.melt(id_vars='Year',value_vars=[i for i in fl_unemp.columns if i!='Year'],var_name='month_of_year',\n",
    "                        value_name='unemployment_pct')\n",
    "fl_unemp.loc[:, 'month_of_year'] = fl_unemp.month_of_year.apply(lambda x:pd.to_datetime(x,format='%b')).dt.month\n",
    "fl_unemp.columns = ['year_of_calendar','month_of_year','unemployment_pct']\n",
    "fl_unemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us cpi\n",
    "us_cpi = pd.read_excel('../data/us_cpi.xlsx',usecols='A:M',skiprows=11)\n",
    "us_cpi = us_cpi.melt(id_vars='Year',value_vars=[i for i in us_cpi.columns if i!='Year'],var_name='month_of_year',\n",
    "                        value_name='cpi')\n",
    "us_cpi.loc[:, 'month_of_year'] = us_cpi.month_of_year.apply(lambda x:pd.to_datetime(x,format='%b')).dt.month\n",
    "us_cpi.columns = ['year_of_calendar','month_of_year','cpi']\n",
    "us_cpi.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
